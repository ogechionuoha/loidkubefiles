apiVersion: apps/v1
kind: Deployment
metadata:
    name: pytorchmlnotebookgpu
    namespace: ogechiproject
    label:
        app: pytorchMLNotebook
        group: ogechi
spec:
    replicas: 1
    selector:
        matchLabels:
            app: pytorchMLNotebook
    template:
        metadata:
            labels:
                app: pytorchMLNotebook
                deployment: pythonMLNotebookGPU
                group: ogechi
        spec:
            nodeSelector:
                node-role.ida/gputitan: "true"
                # node-role.ida/gpu2080ti: "true"
            volumes:
                - name: nfs-access
                  persistentVolumeClaim:
                    claimName: ogechivol1claim
            securityContext: {}
            serviceAccount: default
            containers:
                - name: pytorchmlcontainer
                  image: anibali/pytorch
                  resources:
                    requests:
                        cpu: "2000m"
                        memory: "16Gi"
                        nvidia.com/gpu: 1
                    limits:
                        cpu: "2500m"
                        memory: "26Gi"
                        nvidia.com/gpu: 1
                  command: [ "/bin/bash", "-ec"]
                  args: [ date; sleep 10; echo 'Hello from the Kubernetes cluster'; sleep 1; while true; do sleep 20; done;]    
                  ports:
                    - containerPort: 8888
                  volumeMounts:
                    - mountPath: /nfs
                      name: nfs-access
                      subPath: notebooks
                
                
